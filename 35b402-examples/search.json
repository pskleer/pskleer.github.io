[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python implementations for 35B402",
    "section": "",
    "text": "1 Probability and statistics\nIn this chapter we will show various visualizations and Python basics of concepts we have seen in the course Probability and Statistics (35B402).\nMore precisely, this chapter consists of two parts: links to interactive applications illustrating concepts and examples seen in class, and Python basics for working with probability distributions and randomly generated data.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probability and statistics</span>"
    ]
  },
  {
    "objectID": "index.html#probability-distributions",
    "href": "index.html#probability-distributions",
    "title": "Python implementations for 35B402",
    "section": "1.1 Probability distributions",
    "text": "1.1 Probability distributions\nThe stats module of SciPy has many built-in probability distributions. Each distribution can be seen as an object on which various methods can be performed (such as accessing its probability density function or summary statistics like the mean and median).\n\nimport numpy as np\nimport scipy.stats as stats\n\nIn this section we will focus on continuous probability distributions. SciPy also has many built-in discete probability distributions.\nA list of all continuous distributions that are present in the stats module can be found here; they are so-called stats.rv_continuous objects. We can instantiate a distributional object by using scipy.stats.dist_name where dist_name is the name of a built-in (continuous) probability distribution in the mentioned list.\nMany distributions have input parameters scale and loc that model the scale and location of the distribution, respectively. Depending on the distribution that is considered, these parameters have different meanings.\nAs an example, the normal distribution has probability density function \nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2} } e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n which is parameterized by \\mu and \\sigma.\nIn Python \\mu is the loc parameter, and \\sigma the scale parameter. To figure out the function of the scale and loc parameter, you can check the documentation (which can be found here for the Normal distribution).\n\n\n\nDocumentation of the normal distribution\n\n\nAll distributions have default values for these parameters, which are typically loc=0 and scale = 1.\n\n# Create normal distribution object with mu=0, sigma=1\ndist_norm = stats.norm(loc=0, scale=1)\n\nOnce a distribution object has been instantiated, we can use methods (i.e., functions) to obtain various properties of the distribution, such as its probability density function (pdf), cumulative density function (cdf) and summary statistics such as the mean, variance and median (or, more general, quantiles).\nWe give a list of some common methods for a distribution object named dist_name. We start with common functions associated with a probability distribution.\n\ndist_name.pdf(x): Value f(x) where f is the pdf of the distribution.\ndist_name.cdf(x): Value F(x) where F is the cdf of the distribution.\n\n\n\nx = 1\nprint(dist_norm.pdf(x))\n\n0.24197072451914337\n\n\nAll the above functions are vectorized, meaning here that they can also take one-dimensional Numpy arrays as input, in which case they return the requested value for every element in the array.\n\nx = np.array([1, 3, 5.5])\nprint(dist_norm.pdf(x)) # Gives probability density function evaluated in x = 1, 3, 5.5\n\n[2.41970725e-01 4.43184841e-03 1.07697600e-07]\n\n\nWe can also access various summary statistics:\n\ndist_name.mean(): Returns mean of the distribution\ndist_name.var(): Returns variance of the distribution\ndist_name.median(): Returns median of the distribution\n\n\ndist_norm = stats.norm(loc=0,scale=2)\n\nmean =  dist_norm.mean()\nvariance = dist_norm.var()\nmedian = dist_norm.median()\n\nprint(\"Mean of the distribution is\", mean)\nprint(\"Variance of the distribution is\", variance)\nprint(\"Median of the distribution is\", median)\n\nMean of the distribution is 0.0\nVariance of the distribution is 4.0\nMedian of the distribution is 0.0\n\n\n\nAs a final application of density functions, we show how they can be used to compute convolutions.\n\nInsight 3.19: Convolution of three distributions\nFollowing the setting of Insight 3.19 seen in class, let Z = X + Y + U with X \\sim \\text{LogNormal}(\\mu,\\sigma^2), Y \\sim \\text{Exp}(\\lambda) and U \\sim U(a,b), that is, Z is the sum of a log-normal, exponential and uniform distribution.\nThe goal is to create for a grid of z-values, the corresponding probability density f_Z(z)-values. Computing convolutions can be done easily with the fftconvolve() function from SciPy’s signal package. Here is this is done in a two-step approach.\nFirst, the pdf f_{X+Y} of the convolution of X and Y is computed, and then afterwards the pdf f_Z = F_{(X+Y) + U} as the convolution of X+Y and U is computed.\nWe do not explain the code below in detail, but give it here to illustrate that convolutions can be numerically computed with relatively small (programming) effort as opposed to a typically hard analysis of the corresponding integral analytically.\n\nimport numpy as np\nfrom scipy.stats import lognorm, expon, uniform\nfrom scipy.signal import fftconvolve\nimport matplotlib.pyplot as plt\n\n# Parameters (as in Insight 3.19)\nmu = 0.0\nsigma = 0.5\nlam = 1.0\na, b = 0.0, 2.0\n\n# Grid\ndx = 0.001\nx_max = 20\nx = np.arange(0, x_max, dx)\n\n# PDFs\nf_X = lognorm.pdf(x, s=sigma, scale=np.exp(mu))\nf_Y = expon.pdf(x, scale=1/lam)\nf_U = uniform.pdf(x, loc=a, scale=b - a)\n\n# First convolution: X + Y. \n# f_XY is pdf of X + Y\nf_XY = fftconvolve(f_X, f_Y, mode=\"full\") * dx\n\n# Second convolution: (X + Y) + U: \n# f_Z is df of Z\nf_Z = fftconvolve(f_XY, f_U, mode=\"full\") * dx\n\n# Corresponding grid for Z\nz = np.arange(0, len(f_Z)) * dx\n\nIn the code above the final array z contains various values so thatf_Z[i] is the pdf value of Z of the i-th element z[i] in z. We can also visualize the resulting pdf by plotting z against f_Z.\nIf you want to know more about plotting functions with Python, you can have a look, e.g.,  here .\n\n# Plot\nplt.figure(figsize=(8, 4))\nplt.plot(z, f_Z, label=\"PDF of Z = X + Y + U\")\nplt.xlim(0, 15)\nplt.xlabel(\"z\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.grid()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probability and statistics</span>"
    ]
  },
  {
    "objectID": "index.html#simulation-based-inference",
    "href": "index.html#simulation-based-inference",
    "title": "Python implementations for 35B402",
    "section": "1.2 Simulation-based inference",
    "text": "1.2 Simulation-based inference\n\n1.2.1 Data generation\n\n\n1.2.2 Examples from Chapter 7",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probability and statistics</span>"
    ]
  },
  {
    "objectID": "index.html#interactive-visualizations-seen-in-class",
    "href": "index.html#interactive-visualizations-seen-in-class",
    "title": "Python implementations for 35B402",
    "section": "1.3 Interactive visualizations seen in class",
    "text": "1.3 Interactive visualizations seen in class\n\nExample 2.33\nIn this section we provide an interactive application for the visualization of the bivarate Normal distribution. This tool gives the option to vary the covariance matrix entries in four different ways (each with their own characteristic). You can also control which probability contour is plotted.\nThe means are fixed at \\mu_X = 5 and \\mu_Y = 50. The reason these cannot be varied is because this only give rise to a translation of the elements in the application.\n\n\n\nShow code generating the plot below\nimport pandas as pd\nimport numpy as np\nimport altair as alt\nfrom scipy.stats import chi2\nalt.data_transformers.enable(\"vegafusion\")\n\n# Different regimes for correlation/covariance\nsigma_values = [(4,25,8), \n                (4,25,-8),\n                (4,25,0),\n                (3,6,4)]\n\n\n# Initial data frames \ndf_points = pd.DataFrame({\n    \"x\": pd.Series(dtype=\"float64\"),\n    \"y\": pd.Series(dtype=\"float64\"),\n    \"name\": pd.Series(dtype=\"string\"),\n    \"sigma\": pd.Series(dtype=\"object\"),\n})\n\ndf_line = pd.DataFrame({\n    \"x\": pd.Series(dtype=\"float64\"),\n    \"y\": pd.Series(dtype=\"float64\"),\n    \"name\": pd.Series(dtype=\"string\"),\n    \"sigma\": pd.Series(dtype=\"object\"),\n})\n\ndf_ellipses = pd.DataFrame({\n    \"x\": pd.Series(dtype=\"float64\"),\n    \"y\": pd.Series(dtype=\"float64\"),\n    \"p\": pd.Series(dtype=\"float64\"),\n    \"theta\": pd.Series(dtype=\"float64\"),\n    \"name\": pd.Series(dtype=\"string\"),\n    \"sigma\": pd.Series(dtype=\"object\"),\n})\n\n# Mean values\nmu_x = 5\nmu_y = 50\n\n# Slider for probability p\np_values = np.arange(0.05, 1.0, 0.05)\np_slider = alt.param(\n        name=\"p\",\n        value=0.95,\n        bind=alt.binding_range(min=p_values.min(), \n                                max=p_values.max(), \n                                 step=0.05,\n                                  name=\"Probability contour for p = \")\n)\n\nsigma_selector = alt.param(\n    name=\"sigma\",\n    value=sigma_values[0],  # Set the default value\n    bind=alt.binding_select(options=sigma_values, \n                                name=\"Select covariance matrix σₓ, σᵧ, σₓᵧ = \")\n)\n\nfor sigmas in sigma_values:  \n    sigma_x = sigmas[0]\n    sigma_y = sigmas[1]\n    sigma_xy = sigmas[2]\n\n    # Means and covariance\n    mu = np.array([mu_x, mu_y])\n    Sigma = np.array([[sigma_x, sigma_xy],\n                      [sigma_xy, sigma_y]])\n\n    # Random data\n    np.random.seed(42)\n    data = np.random.multivariate_normal(mu, Sigma, size=500)\n    data_x, data_y = data[:,0], data[:,1]\n\n    # Correlation line\n    corr = np.corrcoef(data_x, data_y)[0,1]\n    slope = corr * (np.std(data_y)/np.std(data_x))\n    intercept = np.mean(data_y) - slope * np.mean(data_x)\n    x_line = np.linspace(np.min(data_x), np.max(data_x), 100)\n    y_line = intercept + slope * x_line\n\n    # print(df_points)\n    df_points_new = pd.DataFrame({\"x\": data_x, \"y\": data_y, \n            \"name\": \"Generated data (points)\", \"sigma\" : [sigmas] * len(data_x)})\n    df_points = pd.concat([df_points, df_points_new],ignore_index=True)\n\n    df_line_new = pd.DataFrame({\"x\": x_line, \"y\": y_line, \n            \"name\": \"Correlation (line)\",\"sigma\" : [sigmas] * len(x_line)})\n    df_line = pd.concat([df_line, df_line_new],ignore_index=True)\n\n    # Precompute ellipses for all p\n    def probability_ellipse(mu, Sigma, p, n_points=200):\n        c = chi2.ppf(p, df=2)\n        vals, vecs = np.linalg.eigh(Sigma)\n        axes = np.sqrt(vals * c)\n        theta = np.linspace(0, 2*np.pi, n_points)\n        ellipse = vecs @ np.vstack([axes[0]*np.cos(theta), axes[1]*np.sin(theta)])\n        ellipse[0] += mu[0]\n        ellipse[1] += mu[1]\n        return pd.DataFrame({\"x\": ellipse[0], \"y\": ellipse[1], \"theta\": theta, \"p\": p, \n            \"name\": \"Probability contour (ellipse)\",\n            \"sigma\" : [sigmas] * len(ellipse[0])}).sort_values(\"theta\") \n\n    df_ellipses_new = pd.concat([probability_ellipse(mu, Sigma, p) for p in p_values])\n    df_ellipses = pd.concat([df_ellipses, df_ellipses_new],ignore_index=True)\n\n# Define the domain limits\nx_min, x_max = -3, 13\ny_min, y_max = 30, 70\n\ncolor_legend=alt.Scale(domain=[\"Generated data (points)\", \n                               \"Correlation (line)\", \n                               \"Probability contour (ellipse)\"], \n                                   range=[\"grey\", \"red\", \"blue\"])\n\n# Filter points within domain\ndf_points_filtered = df_points[\n    (df_points[\"x\"] &gt;= x_min) & (df_points[\"x\"] &lt;= x_max) &\n    (df_points[\"y\"] &gt;= y_min) & (df_points[\"y\"] &lt;= y_max)\n]\n\n# Now use df_points_filtered for the data points\npoints = alt.Chart(df_points_filtered).transform_filter(\n    (alt.datum.sigma[0] == sigma_selector[0]) &\n    (alt.datum.sigma[1] == sigma_selector[1]) &\n    (alt.datum.sigma[2] == sigma_selector[2])\n).mark_circle(size=40, opacity=0.5).encode(\n    x=\"x:Q\", y=\"y:Q\", \n    color=alt.Color(\"name:N\", \n                   scale=color_legend,\n                   legend=alt.Legend(title=\"Element type\"))\n)\n\n# Line can also be filtered if needed\ndf_line_filtered = df_line[\n    (df_line[\"x\"] &gt;= x_min) & (df_line[\"x\"] &lt;= x_max) &\n    (df_line[\"y\"] &gt;= y_min) & (df_line[\"y\"] &lt;= y_max)\n]\n\nline = alt.Chart(df_line_filtered).transform_filter(\n    (alt.datum.sigma[0] == sigma_selector[0]) &\n    (alt.datum.sigma[1] == sigma_selector[1]) &\n    (alt.datum.sigma[2] == sigma_selector[2])\n).mark_line(strokeWidth=2).encode(\n    x=\"x:Q\", \n    y=\"y:Q\",\n    color=alt.Color(\"name:N\", \n                   scale=color_legend,\n                   legend=alt.Legend(title=\"Element type\"))\n)\n\n# Ellipse can be filtered similarly\ndf_ellipses_filtered = df_ellipses[\n    (df_ellipses[\"x\"] &gt;= x_min) & (df_ellipses[\"x\"] &lt;= x_max) &\n    (df_ellipses[\"y\"] &gt;= y_min) & (df_ellipses[\"y\"] &lt;= y_max)\n]\n\nellipse = alt.Chart(df_ellipses_filtered).transform_filter(\n   (alt.datum.p - p_slider) ** 2 &lt; 1e-6, \n    (alt.datum.sigma[0] == sigma_selector[0]) &\n    (alt.datum.sigma[1] == sigma_selector[1]) &\n    (alt.datum.sigma[2] == sigma_selector[2])\n).mark_line(strokeDash=[5,5]).encode(\n    x=\"x:Q\", y=\"y:Q\", order=\"theta\",\n    color=alt.Color(\"name:N\", \n                   scale=color_legend,\n                   legend=alt.Legend(title=\"Element type\"))\n)\n\n# Combine charts\nchart = (points + line + ellipse).add_params(sigma_selector,p_slider).encode(\n    x=alt.X(\"x:Q\", scale=alt.Scale(domain=[x_min, x_max])),\n    y=alt.Y(\"y:Q\", scale=alt.Scale(domain=[y_min, y_max]))\n).properties(\n    width=500, height=350, title={\n            \"text\": {\n                \"expr\": \"'Bivariate Normal distribution with probability contour for p = ' + format(p, \\\".2f\\\")\"\n            },\n            \"anchor\": \"middle\"\n        }\n)\n\nchart\n\n\n\n\n\n\n\n\n\n\nExample 2.50\nHere we give an interactive visualizaiton of Example 2.50 illustrating the tail behaviour of the Gamma(\\alpha,\\beta)-Mixed Poisson distribution as \\alpha varies.\n\n\n\nShow code generating the plot below\nimport numpy as np\nimport pandas as pd\nimport altair as alt\nfrom scipy.stats import nbinom\n\n# -----------------------------\n# Parameters\n# -----------------------------\nk2 = np.arange(0, 31)\nbeta_nb = 1.0\np_nb = beta_nb / (beta_nb + 1)\n\n# Range of alpha values for slider\nalpha_values = np.arange(1.0, 15.1, 0.5)\n\n# -----------------------------\n# Build DataFrame\n# -----------------------------\nrows = []\nfor alpha in alpha_values:\n    pmf = nbinom(n=alpha, p=p_nb).pmf(k2)\n    tail = 1 - nbinom(n=alpha, p=p_nb).cdf(k2 - 1)\n\n    for k, p, t in zip(k2, pmf, tail):\n        rows.append({\n            \"k\": k,\n            \"value\": p,\n            \"type\": \"PMF\",\n            \"alpha\": alpha\n        })\n        if k &gt; 0:  # avoid log(0)\n            rows.append({\n                \"k\": k,\n                \"value\": t,\n                \"type\": \"Tail\",\n                \"alpha\": alpha\n            })\n\ndf = pd.DataFrame(rows)\n\n# -----------------------------\n# Slider parameter\n# -----------------------------\n\nalpha_slider = alt.param(\n    name=\"alpha\",\n    value=5.0,\n    bind=alt.binding_range(\n        min=alpha_values.min(),\n        max=alpha_values.max(),\n        step=1,\n        name=r\"Dispersion control value α = : \"\n    )\n)\n\nslider_chart = (\n    alt.Chart(pd.DataFrame({\"x\": [0]}))\n    .add_params(alpha_slider)\n    .mark_point(opacity=0)\n    .properties(\n        height=10,\n        title=\" \"\n    )\n)\n\n\n# -----------------------------\n# PMF plot\n# -----------------------------\npmf_chart = (\n    alt.Chart(df[df[\"type\"] == \"PMF\"])\n    .transform_filter(alt.datum.alpha == alpha_slider)\n    .mark_line(interpolate=\"step-after\", strokeWidth=2, color=\"blue\")\n    .encode(\n        x=alt.X(\"k:Q\", title=r\"k\",scale=alt.Scale(domain=[0, 30]),\n                axis=alt.Axis(\n                titleFontSize=15,\n                titleFontWeight='lighter')),\n        y=alt.Y(\"value:Q\", title=r\"P(X = x)\",scale=alt.Scale(domain=[0, 0.5]), \n                axis=alt.Axis(\n                titleFontSize=15,\n                titleFontWeight='lighter')\n               )\n    )\n    .properties(\n        title={\"text\": {\n                        \"expr\": \"'Gamma(α=' + alpha + ',β=1)-Mixed Poisson (Negative Binomial)'\"\n                    },\n                    \"anchor\": \"middle\"\n                },\n        width=225,\n        height=200\n    )\n)\n\n# -----------------------------\n# Tail probability plot (log-log)\n# -----------------------------\ntail_chart = (\n    alt.Chart(df[df[\"type\"] == \"Tail\"])\n    .transform_filter(alt.datum.alpha == alpha_slider)\n    .mark_line(strokeWidth=2, color=\"blue\")\n    .encode(\n        x=alt.X(\"k:Q\", title=r\"k\", scale=alt.Scale(type=\"log\"),axis=alt.Axis(\n                titleFontSize=15,\n                titleFontWeight='lighter',\n            )),\n        y=alt.Y(\n            \"value:Q\",\n            scale=alt.Scale(type=\"log\", domain=[1e-9, 1]),\n            title=r\"P(X ≥ x)\",\n            axis=alt.Axis(\n                titleFontSize=15,\n                titleFontWeight='lighter',\n            )\n        )\n    )\n    .properties(\n        title={\"text\": {\n                        \"expr\": \"'Corresponding tail probability (Negative Binomial)'\"\n                    },\n                    \"anchor\": \"middle\"\n                },\n        width=225,\n        height=200\n    )\n)\n\n# -----------------------------\n# Final layout\n# -----------------------------\nfinal_chart = alt.vconcat(\n    slider_chart,\n    pmf_chart | tail_chart\n)\n\nfinal_chart\n\n\n\n\n\n\n\n\n\n\nExample 4.18\nHere we show the convergence of a standardized Gamma(k,1) distribution to a Normal distribution as k increases.\n\n\n\nShow code generating the plot below\nimport numpy as np\nimport pandas as pd\nimport altair as alt\nfrom scipy import stats\nalt.data_transformers.enable(\"vegafusion\")\n\n# -----------------------------\n# Slider values\n# -----------------------------\nk_values = np.arange(2, 100, 1)  # integer k from 1 to 15\nlam = 1.0  # lambda parameter\n\n# x-axis for standardized values\nx = np.linspace(-3, 3, 100)\n\n# -----------------------------\n# Build long-form DataFrames for all k values\n# -----------------------------\nrows_pdf = []\nrows_cdf = []\n\nfor k_slider in k_values:\n    # Gamma distribution\n    gamma_dist = stats.gamma(a=k_slider, scale=1/lam)\n    mu = gamma_dist.mean()\n    sigma = gamma_dist.std()\n\n    gamma_pdf = gamma_dist.pdf(mu + sigma * x) * sigma\n    gamma_cdf = gamma_dist.cdf(mu + sigma * x)\n\n    # Standard Normal reference\n    normal_pdf = stats.norm.pdf(x)\n    normal_cdf = stats.norm.cdf(x)\n\n    # PDF rows\n    for xi, gpdf, npdf in zip(x, gamma_pdf, normal_pdf):\n        rows_pdf.append({\"x\": xi, \"value\": gpdf, \"distribution\": \"Standardized Gamma\", \"k_slider\": k_slider})\n        rows_pdf.append({\"x\": xi, \"value\": npdf, \"distribution\": \"Normal(0,1)\", \"k_slider\": k_slider})\n\n    # CDF rows\n    for xi, gcdf, ncdf in zip(x, gamma_cdf, normal_cdf):\n        rows_cdf.append({\"x\": xi, \"value\": gcdf, \"distribution\": \"Standardized Gamma\", \"k_slider\": k_slider})\n        rows_cdf.append({\"x\": xi, \"value\": ncdf, \"distribution\": \"Normal(0,1)\", \"k_slider\": k_slider})\n\ndf_pdf = pd.DataFrame(rows_pdf)\ndf_cdf = pd.DataFrame(rows_cdf)\n\n# -----------------------------\n# Slider parameter\n# -----------------------------\nk_slider_param = alt.param(\n    name=\"k\",\n    value=5,\n    bind=alt.binding_range(min=k_values.min(), \n                           max=k_values.max(), \n                           step=1,\n                           name=r\"Value k = \")\n)\n\nslider_chart = (\n    alt.Chart(pd.DataFrame({\"x\": [0]}))\n    .add_params(k_slider_param)\n    .mark_point(opacity=0)\n    .properties(height=10)\n)\n\n# -----------------------------\n# PDF chart\n# -----------------------------\npdf_chart = (\n    alt.Chart(df_pdf)\n    .transform_filter(alt.datum.k_slider == k_slider_param)\n    .mark_line()\n    .encode(\n        x=alt.X(\"x\", scale=alt.Scale(domain=[-3, 3]), title=\"x\",axis=alt.Axis(\n                    titleFontSize=15, # Size\n                    titleFontWeight='lighter')),\n        y=alt.Y(\"value\", scale=alt.Scale(domain=[-0.05, 0.6]), title=\"f(x)\", axis=alt.Axis(\n                    titleFontSize=15, # Size\n                    titleFontWeight='lighter')),\n        color=alt.Color(\"distribution:N\", legend=alt.Legend(title=\"Distribution\"))\n    )\n    .properties(width=225, height=200, title=\"Probability Density Function\")\n)\n\n# -----------------------------\n# CDF chart\n# -----------------------------\ncdf_chart = (\n    alt.Chart(df_cdf)\n    .transform_filter(alt.datum.k_slider == k_slider_param)\n    .mark_line()\n    .encode(\n        x=alt.X(\"x\", scale=alt.Scale(domain=[-3, 3]), title=\"x\",axis=alt.Axis(\n                    titleFontSize=15, # Size\n                    titleFontWeight='lighter')),\n        y=alt.Y(\"value\", scale=alt.Scale(domain=[-0.05, 1]), title=\"F(x)\",axis=alt.Axis(\n                    titleFontSize=15, # Size\n                    titleFontWeight='lighter')),\n        color=alt.Color(\"distribution:N\", legend=alt.Legend(title=\"Distribution\"))\n    )\n    .properties(width=225, height=200, title=\"Cumulative Density Function\")\n)\n\n# -----------------------------\n# Combine slider + charts\n# -----------------------------\nfinal_chart = alt.vconcat(\n    slider_chart,\n    pdf_chart | cdf_chart\n).properties(title={\n                \"text\": {\n                    \"expr\": \"'Standardized Gamma(k=' + k + ',1) and Normal(0,1) distribution'\"\n                },\n                \"anchor\": \"middle\"\n            })\n\nfinal_chart\n\n\n\n\n\n\n\n\n\n\nExample 4.28\nHere we show convergence of the standardized sum of Poisson(1) random variables to a Normal distribution. Note that this concerns “convergence” of a discrete distribution to a continuous distribution.\n\n\n\nShow code generating the plot below\nimport numpy as np\nimport pandas as pd\nimport altair as alt\nfrom scipy import stats\n# alt.data_transformers.enable(\"vegafusion\") #Requires Vegafusion \"conda install -c conda-forge vegafusion vl-convert-python\" in Anaconda prompt\n\n# -----------------------------\n# Slider values\n# -----------------------------\nk_values = np.arange(1, 50, 1)\n\n# -----------------------------\n# Build DataFrames separately\n# -----------------------------\nrows_pois = []\nrows_norm = []\n\nfor k in k_values:\n    # --- Poisson sum ---\n    pois_dist = stats.poisson(mu=k)\n    multiple = 4 # This value should be the same as the x_range later one; otherwise there are also x-values outside the plotted range which makes the legend jump around. This is a rule of thumb, though.\n    s_vals = np.arange(0, k + multiple * np.sqrt(k)) # Most mass falls in this support\n\n    z_vals = (s_vals - k) / np.sqrt(k)\n    pmf_vals = pois_dist.pmf(s_vals)\n\n    bin_width = 1 / np.sqrt(k)\n\n    for z, p in zip(z_vals, pmf_vals):\n        rows_pois.append({\n            \"z\": z,\n            \"value\": p / bin_width,\n            \"k_slider\": k,\n            \"legend\": \"Standardized Poisson Sum\"\n        })\n\n    # --- Normal reference ---\n    x_range = multiple\n    x = np.linspace(-x_range, x_range, 100)\n    normal_pdf = stats.norm.pdf(x)\n\n    for xi, yi in zip(x, normal_pdf):\n        rows_norm.append({\n            \"z\": xi,\n            \"value\": yi,\n            \"k_slider\": k,\n            \"legend\": \"Normal(0,1)\"\n        })\n\ndf_pois = pd.DataFrame(rows_pois)\ndf_norm = pd.DataFrame(rows_norm)\n\n# -----------------------------\n# Slider parameter\n# -----------------------------\nk_slider_param = alt.param(\n    name=\"k\",\n    value=1,\n    bind=alt.binding_range(\n        min=k_values.min(),\n        max=k_values.max(),\n        step=1,\n        name=\"Value k = \"\n    )\n)\n\nslider_chart = (\n    alt.Chart(pd.DataFrame({\"x\": [0]}))\n    .add_params(k_slider_param)\n    .mark_point(opacity=0)\n    .properties(height=0)\n)\n\n\n# -----------------------------\n# Common legend properties\n# -----------------------------\ncolor_encoding = alt.Color(\n    \"legend:N\",\n    scale=alt.Scale(\n        domain=[\"Standardized Poisson Sum\", \"Normal(0,1)\"],\n        range=[\"pink\", \"blue\"]\n    ),\n    legend=alt.Legend(title=\"Distribution\", orient=\"right\")  # &lt;-- left side\n)\n\n# -----------------------------\n# Poisson bars\n# -----------------------------\n# Define the width calculation\npmf_chart = (\n    alt.Chart(df_pois)\n    .transform_filter(alt.datum.k_slider == k_slider_param)  # Filter based on slider value\n    .mark_bar(opacity=0.7,width= 25 * k_slider_param ** (-0.5)) # Set heuristically by inspection\n    .encode(\n        x=alt.X(\"z:Q\", title=\"Standardized value\", scale=alt.Scale(domain=[-x_range, x_range]),             \n                axis=alt.Axis(\n                    titleFontSize=15, # Size\n                    titleFontWeight='lighter')),\n        y=alt.Y(\"value:Q\", title=r\"Density\",\n                axis=alt.Axis(\n                    titleFontSize=15, # Size\n                    titleFontWeight='lighter')), # Amount of bold face\n        color=color_encoding\n    )\n)\n\n\n# -----------------------------\n# Normal line\n# -----------------------------\nnormal_curve = (\n    alt.Chart(df_norm)\n    .transform_filter(alt.datum.k_slider == k_slider_param)\n    .mark_line(size=3)\n    .encode(\n        x=alt.X(\"z:Q\", scale=alt.Scale(domain=[-x_range,x_range])),\n        y=\"value:Q\",\n        color=color_encoding\n    )\n)\n\n\n# -----------------------------\n# Final chart\n# -----------------------------\nfinal_chart = alt.vconcat(\n    slider_chart,\n    (pmf_chart + normal_curve).properties(\n        title={\n            \"text\": {\n                \"expr\": \"'Standardized sum of k = ' + k + ' Poisson(1) variables'\"\n            },\n            \"anchor\": \"middle\"\n        }, width=350, height=300\n    )\n)\n\nfinal_chart\n\n\n\n\n\n\n\n\n\n\nExample 4.29\nHere we show the convergence of the sum of bimodal PDFs to a Normal distribution with the same mean and variance.\n\n\n\nShow code generating the plot below\nimport numpy as np\nimport pandas as pd\nimport altair as alt\nfrom scipy.signal import convolve\nalt.data_transformers.enable(\"vegafusion\")\n\ndef bimodal_pdf(x, mu1, sigma1, mu2, sigma2, w1, w2):\n    \"\"\"Compute a bimodal PDF as a weighted sum of two normal distributions.\"\"\"\n    pdf1 = (1 / (np.sqrt(2 * np.pi) * sigma1)) * np.exp(-0.5 * ((x - mu1) / sigma1) ** 2)\n    pdf2 = (1 / (np.sqrt(2 * np.pi) * sigma2)) * np.exp(-0.5 * ((x - mu2) / sigma2) ** 2)\n    return w1 * pdf1 + w2 * pdf2\n\ndef compute_convolution(pdf1, pdf2, dx):\n    \"\"\"Compute the convolution of two PDFs and normalize the result.\"\"\"\n    conv = convolve(pdf1, pdf2, mode='full') * dx\n    return conv / np.sum(conv * dx)\n\n# Parameters for the bimodal distribution\nmu1, sigma1 = 2.0, 0.5\nmu2, sigma2 = 6.0, 1.0\nw1, w2 = 0.5, 0.5\n\n# Compute mean and variance of the bimodal distribution\nmu_bimodal = w1 * mu1 + w2 * mu2\nvar_bimodal = w1 * (sigma1**2 + mu1**2) + w2 * (sigma2**2 + mu2**2) - mu_bimodal**2\nsigma_bimodal = np.sqrt(var_bimodal)\n\n# Initial x range and PDF (wide enough)\nx = np.linspace(-5, 25, 100)\ndx = x[1] - x[0]\ny = bimodal_pdf(x, mu1, sigma1, mu2, sigma2, w1, w2)\n\n# DataFrames for Altair plotting\ndf_list = []\ndf_normal_list = []\n\n# n values\nn_values = np.arange(1, 21, 1)\n\nfor n in n_values:\n    pdf_n = y.copy()\n    x_n = x.copy()\n\n    # Perform (n-1) convolutions\n    for _ in range(n - 1):\n        x_n_new = np.linspace(x_n[0] + x[0], x_n[-1] + x[-1], len(pdf_n) + len(y) - 1)\n        pdf_n = compute_convolution(pdf_n, y, dx)\n        x_n = x_n_new\n\n    # Compute cumulative sum for approximate CDF\n    cdf_n = np.cumsum(pdf_n) * dx\n    # Determine 0.01 and 0.99 quantiles\n    x_min = np.interp(0.0001, cdf_n, x_n)\n    x_max = np.interp(0.9999, cdf_n, x_n)\n\n    # Mask to keep only points in [x_min, x_max]\n    mask = (x_n &gt;= x_min) & (x_n &lt;= x_max)\n    x_n_trim = x_n[mask]\n    pdf_n_trim = pdf_n[mask]\n\n    # Add bimodal convolution data\n    for xi, pi in zip(x_n_trim, pdf_n_trim):\n        df_list.append({\"x\": xi, \"PDF of bimodal sum\": pi, \"n\": n, \"legend\": \"Sum of Bimodal PDFs\"})\n\n    # Normal approximation data (same x-range)\n    mu_normal = n * mu_bimodal\n    sigma_normal = np.sqrt(n) * sigma_bimodal\n    pdf_normal = (1 / (np.sqrt(2 * np.pi) * sigma_normal)) * np.exp(-0.5 * ((x_n_trim - mu_normal) / sigma_normal) ** 2)\n    for xi, pi in zip(x_n_trim, pdf_normal):\n        df_normal_list.append({\"x\": xi, \"PDF of bimodal sum\": pi, \"n\": n, \"legend\": \"Normal with same mean/variance\"})\n\n# Convert to DataFrames\ndf = pd.DataFrame(df_list)\ndf_normal = pd.DataFrame(df_normal_list)\n\n# Slider\nn_selector = alt.param(\n    name=\"n\",\n    value=1,\n    bind=alt.binding_range(min=n_values.min(), \n                           max=n_values.max(), \n                           step=1, \n                           name=\"Value n = \")\n)\n\n# -----------------------------\n# Common legend properties\n# -----------------------------\ncolor_encoding = alt.Color(\n    \"legend:N\",\n    scale=alt.Scale(\n        domain=[\"Sum of Bimodal PDFs\", \"Normal with same mean/variance\"],\n        range=[\"pink\", \"blue\"]\n    ),\n    legend=alt.Legend(title=\"Distribution\", orient=\"right\") \n)\n\n# Altair plot\nchart_bimodal = alt.Chart(df).add_params(n_selector).transform_filter(\n    alt.datum.n == n_selector\n).mark_area(opacity=0.3).encode(\n    x='x:Q',\n    y='PDF of bimodal sum:Q',\n    color=color_encoding\n)\n\nchart_normal = alt.Chart(df_normal).transform_filter(\n    alt.datum.n == n_selector\n).mark_line(strokeDash=[5,2]).encode(\n    x='x:Q',\n    y='PDF of bimodal sum:Q',\n    color=color_encoding\n)\n\n(chart_bimodal + chart_normal).properties(\n    title={\"text\":{\"expr\":\"'Sum of n = ' + n + ' bimodal PDFs'\"},\"anchor\":\"middle\"}, width=350, height=300\n)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probability and statistics</span>"
    ]
  }
]